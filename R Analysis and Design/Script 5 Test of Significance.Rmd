---
title: "Script 5 Test of Significance"
author: "Eziamaka Clinton"
date: "09/11/2019"
output:
  word_document: default
  html_document: default
---
1.
```{r}
repairs <- c(183,222,303,262,178,232,268,201,244,183,201,140)
n<-12
mu<-0
sd<-50
df<- n-1

z<-(sd/sqrt(n))
alpha<-qt(0.975, df)
me<-alpha*z
x.bar<-mean(repairs)
ci<-c(x.bar-me,x.bar+me)

ci
#This explains that the true mean number of repair time is between the intervals 186.3148 and 249.8518


#(b)
width <- 2*1.96*sd/27
n<-round(width^2)
n

```

2.
$H_0:\mu=502$
$H_a:\mu\ne502$
```{r}
setwd("~/Downloads/DataSet")
myData1 <- read.csv("batteryLife.csv")

x.bar<-mean(myData1[,1])
mu<-502
sd<-23
n<-length(myData1[,1])


z<-(x.bar-mu)/(sd/sqrt(n))

pval<-2*pnorm(z,0,1,lower.tail = TRUE)
pval

#The data provided has a length of 30 samples with an average of 490.0667 and after conducling my hypothesis test at 5% level of significance,we have a pvalue of 0.004485 which is lower than 0.05. So we reject the null hypothesis and conclude that the manufactueres claim that the battery mean life is 502 days is false. 
```

3.
$H_0:The\ professor\ prefers\ Softcover $
$H_a:The\ professor\ prefers\ Hardcover $

```{r}
setwd("~/Downloads/DataSet")
myData2 <- read.csv("Profbooks.csv")

prop.variety <-table(myData2[,'Type'])/length(myData2[,'Type'])
p.0<-0.4666667
p.1<-0.5333333

z<-(p.1-p.0)/sqrt(p.0*(1-p.0)/nrow(myData2))
pval<-2*pnorm(z,0,1,lower.tail = TRUE)
pval

#(b)
# After testing our hypothesis, we can conclude that due to the p value being 1.395227 is large,so we fail to reject the null hyphothesis. And conclude that the professor does not significantly prefer the hardcover books.

#(c)
p0<-p.0
p1<-0.55
n<-15
d<-p0-p1
z<-qnorm(0.05,0,1, lower.tail = FALSE)
beta <-pnorm((d/sqrt(p1*(1-p1)/n))+z*sqrt(p0*(1-p0)/(p1*(1-p1))))
power<-1-beta
power

#(d)
z.alpha<-qnorm(0.875,0,1)
z.beta<-qnorm(0.125,0,1)
n1<-ceiling(p1*(1-p1)*((z.beta-z.alpha*sqrt(p0*(1-p0)/p1*(1-p1)))/(p0-p1))^2)
n1

```

4.
```{r}
setwd("~/Downloads/DataSet")
myData3 <- read.csv("anemia.csv")

#(a)
summary.data <-apply(myData3,2,summary)
summary.data

myData4<-na.omit(myData3)
africanAnemia<-subset(myData4, African.women==1, select = African.women) 
americanAnemia<-subset(myData3, American.women==1, select = American.women)

africanPercentage<-sum(africanAnemia[,1])/nrow(myData4)*100
AmericanPercentage<-sum(americanAnemia[,1])/nrow(myData3)*100
rbind(africanPercentage)
rbind(AmericanPercentage)

```

4b.
$H_0:P_a=P_u$
$H_a:P_a>P_u$
```{r}
X1<-sum(africanAnemia[,1])
n1<-1500
p1<-X1/n1
X2<-sum(americanAnemia[,1])
n2<-1700
p2<-X2/n2
p.hat<-(X1+X2)/(n1+n2)
se<-sqrt(p.hat*(1-p.hat)*(1/n1+1/n2))
z<-(p1-p2)/se
z

pnorm(z,0,1, lower.tail = F)

#After conducting the necessary hyphotesis test on the data given, we have a very small p value of 1.032481e-54. So we reject the null hyphotesis and conclude that the proportion of african women(Pa) suffering from amnesia is higher than that of american women(Pu)


#(c)
x<-c(X1,X2)
n<-c(n1,n2)
prop.test(x,n,alternative ="greater", conf.level = 0.9, correct = F)

#This explains that the true proportion of the difference between african and american women who have anemia lies between the intervals 0.2307886 and 1.

```

5.
```{r}
setwd("~/Downloads/DataSet")
physicalData <- read.csv("physical.csv")
head(physicalData) 

n<-55
```
a.
$H_0:\mu_l-\mu_r=0$
$H_a:\mu_l-\mu_r<0$
```{r}
leftArm<-physicalData$LeftArm
rightArm<-physicalData$RtArm

d<-leftArm-rightArm
t.test(d, mu=0, alternative = "less")
#After testing under a 5% level of significance, we can see that the p value of 0.4948 is greater that 0.05, so we fail to reject the null hyphotesis and conclude that there is no significant difference between the left and right arm.
```

b.
$H_0:\mu_m-\mu_f=0$
$H_a:\mu_m-\mu_f>0$
```{r}
male<-subset(physicalData, Sex=="Male", select = LeftHand)
female<-subset(physicalData, Sex=="Female", select = RtHand)
maleLeftHand<-male[,1]
femaleLeftHand<-female[,1]

t.test(maleLeftHand,femaleLeftHand, var.equal = FALSE, paired = FALSE, alternative = "greater")
#After testing with 5% level of significance, we have a very small p value of 7.173e-05  which is less than 0.05, so we reject the null hyphotesis and conclude that there is a significant difference in the average length in male left hand and female left hand.


#(c)
t.test(maleLeftHand,femaleLeftHand, var.equal = FALSE, paired = FALSE, conf.level = 0.95)
#After testing, we are 95% confident that the true mean difference between the male left hand and the female left hand lies between the intervals 0.6827378 and 1.9425955. 

#(d)
n<-length(femaleLeftHand)
sd.female<-sd(femaleLeftHand)
sig.sq0<-2
chi.sq<-(n-1)*sd.female^2/sig.sq0^2
chi.sq

pchisq(chi.sq,n-1,lower.tail = T)
#After cinducting the above test, and we see that the p value of 02.981696e-07 is less than 0.05. So we reject the null hyphotesis and conclude that the variability of the length of left hand for female is less than 2.

#(e)
chi.sq.left<-qchisq(0.025,n-1)
chi.sq.right<-qchisq(0.975,n-1)


lower.limit<-(n-1)*sd.female^2/chi.sq.right
upper.limit<-(n-1)*sd.female^2/chi.sq.left
CI<-c(lower.limit,upper.limit)
CI
```

6.
```{r}
setwd("~/Downloads/DataSet")
amesData <- read.csv("ames.csv")

#(i.)
responce<-amesData$SalePrice
predictor<-amesData$Gr.Liv.Area
newdf<-data.frame(responce,predictor)

mu <-t(apply(newdf,2,mean))
mu

S.xy <-sum((newdf[,2]-mu[2])*(newdf[,1]-mu[1]))
S.xx <-sum((newdf[,1]-mu[1])^2)
beta1.hat <- S.xy/S.xx
beta0.hat <- mu[2]-beta1.hat*mu[1]

c(beta0.hat, beta1.hat)

fit<-lm(predictor~responce, data = newdf)
fit$coefficients

#(ii)
#predictor = (6.911020e+02) + (4.472379e-03) * responce

#(iii)
res <- resid(fit)
plot(res)
abline(0, 0)
# The plot shows that points are not evenly distributed around the horizontal line through zero. This property shows us that it is not normally distributed. 


#(iv.)
confint(fit)
#This explains that we are 95% confident that our sales price increase by 1, there Gr.Liv.Area will increase on average by  4.310167e-03 to 0.00463459. 

#(v.)
fit<-aov(predictor~responce, data = newdf)
summary(fit)


SSE<-374583113
SSR<-373891308 
SST<-SSE+SSR
r.sq<-1-SSE/SST
r.sq
#From the result, we can say that 49.95% of the variability of the predictor is explained by the responce variable.
```